{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3894b29-d25c-4cdb-be22-323b07a8173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and intizialize\n",
    "import pandas as pd\n",
    "import json\n",
    "from math import isnan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "208083c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read datasets\n",
    "migration_flow = pd.read_csv('migration_flows_bilateral_2015_clean.csv')\n",
    "iso_codes = pd.read_csv('all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed4dd32f-0db5-4ba2-9183-3de5d185fd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy for splitting csv into two without changing the original variable\n",
    "immigrants = migration_flow.copy()\n",
    "emigrants = migration_flow.copy()\n",
    "\n",
    "# Immigrants\n",
    "immigrants = immigrants[immigrants.columns.drop(list(immigrants.filter(regex='EMIGRANTS')))]\n",
    "immigrants = immigrants.iloc[:,:-8]\n",
    "\n",
    "# Emigrants\n",
    "emigrants = emigrants[emigrants.columns.drop(list(emigrants.filter(regex='IMMIGRANTS')))]\n",
    "emigrants = emigrants.iloc[:,:-8] # drop last 8 columns since they are micro nations\n",
    "emigrants.columns = emigrants.columns.str.replace(\"EMIGRANTS_FROM_\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f1a1045-4d0b-4074-824d-d463809afb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to rename column names\n",
    "countries = emigrants.columns[2:] \n",
    "\n",
    "# Create a dictionary with country names as key and index as value\n",
    "country_dict = {key: json.dumps(idx) for idx, key in enumerate(countries)}\n",
    "\n",
    "# Replace column headers with numbers instead of country names\n",
    "emigrants.rename(columns=country_dict, inplace=True) \n",
    "\n",
    "# convert dataframe to dictionary\n",
    "flow = emigrants.iloc[:,2:].to_dict(orient='index')\n",
    "\n",
    "# remove all nan values so dictionary is clean \n",
    "for i in flow: \n",
    "    for j in list(flow[i]):\n",
    "        if isnan(flow[i][j]):\n",
    "            del flow[i][j]\n",
    "flower = json.dumps(flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e1ff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the flow dictionary values to column in dataframe where the key is row number\n",
    "emigrants_15 = emigrants.iloc[:,1:2]\n",
    "emigrants_15['flows'] = pd.Series(flow)\n",
    "emigrants_15['short'] = emigrants_15['COUNTRY'].str[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84a88f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange iso dataset for join with migration dataset\n",
    "iso_codes['name'] = iso_codes['name'].str.upper()\n",
    "iso = iso_codes.iloc[:,:2]\n",
    "iso = iso.rename(columns = {'name':'COUNTRY', 'alpha-2':'ISO Code'})\n",
    "iso['short'] = iso['COUNTRY'].str[:4]\n",
    "iso = iso.iloc[:,1:3]\n",
    "\n",
    "# Actual join via merge()\n",
    "iso_emigrants = pd.merge(emigrants_15, iso, how=\"left\", on=['short'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc59dadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual data cleaning -> future check if values are correctly assigned!\n",
    "\n",
    "# Cleaning ISO values\n",
    "iso_emigrants.xs(39)['ISO Code'] = 'CV'\n",
    "iso_emigrants.xs(40)['ISO Code'] = 'MQ' # As of now Martinique \n",
    "iso_emigrants.xs(44)['ISO Code'] = 'JE' # As of now Jersey\n",
    "iso_emigrants.xs(53)['ISO Code'] = 'CI'\n",
    "iso_emigrants.xs(59)['ISO Code'] = 'CD'\n",
    "iso_emigrants.xs(74)['ISO Code'] = 'FO'\n",
    "iso_emigrants.xs(125)['ISO Code'] = 'LA'\n",
    "iso_emigrants.xs(162)['ISO Code'] = 'NA'\n",
    "iso_emigrants.xs(193)['ISO Code'] = 'PF' # As of now French Polynesia\n",
    "iso_emigrants.xs(197)['ISO Code'] = 'RE'\n",
    "iso_emigrants.xs(323)['ISO Code'] = 'VA'\n",
    "\n",
    "# We do not have values for North/South Korea\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1751cf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a csv file to join in arcGis\n",
    "iso_emigrants.to_csv('emi_15_flow.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f92dff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reintroduce the argis geoJson for further processing\n",
    "f = open('emigrants_15_4326.geoJson', 'r')\n",
    "data = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4559c11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change flows to json format instead of string\n",
    "for i in range(len(data['features'])):\n",
    "    flow_json = iso_emigrants['flows'][i]\n",
    "    data['features'][i]['properties']['flows'] = json.dumps(flow_json)\n",
    "\n",
    "for i in range(len(data['features'])):\n",
    "    flow_json = json.loads(data['features'][i]['properties']['flows'])\n",
    "    data['features'][i]['properties']['flows'] = flow_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd5783b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a centroid attribute where x,y are elements in list centroid \n",
    "for i in data['features']:\n",
    "    i['geometry']['centroid'] = [i['properties']['X'],i['properties']['Y']]\n",
    "\n",
    "# X is long, y is lat in dataset from arcgis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "135777de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OBJECTID': 7,\n",
       " 'Country': 'Samoa',\n",
       " 'ISO Code': 'WS',\n",
       " 'Affiliation': 'Samoa',\n",
       " 'Affiliation ISO Code': 'WS',\n",
       " 'X': -172.1594594644777,\n",
       " 'Y': -13.758366525659419,\n",
       " 'Shape_Length': 3.0196618946939964,\n",
       " 'Shape_Area': 0.24551890561299944,\n",
       " 'COUNTRY': 'SAMOA',\n",
       " 'flows': {'5': -618288.0,\n",
       "  '37': 8662.0,\n",
       "  '38': 0,\n",
       "  '41': 31.0,\n",
       "  '47': 997.0,\n",
       "  '56': 75667.0,\n",
       "  '88': 9252.0,\n",
       "  '141': 235.0,\n",
       "  '143': 839.0,\n",
       "  '167': 0,\n",
       "  '168': 5867.0,\n",
       "  '174': 1186.0,\n",
       "  '184': 6441.0,\n",
       "  '196': 5917.0,\n",
       "  '235': 290.0},\n",
       " 'short': ''}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['features'][5]['properties']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "488da658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Json File\n",
    "json_object = json.dumps(data)\n",
    "with open('e15.json', 'w') as outfile:\n",
    "    outfile.write(json_object)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
